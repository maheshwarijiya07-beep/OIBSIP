# Iris Flower Classification with Machine Learning
# This script trains and evaluates multiple ML models on the Iris dataset

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.datasets import load_iris

def main():
    # Load the Iris dataset
    print("="*70)
    print("IRIS FLOWER CLASSIFICATION")
    print("="*70)
    print("\nLoading Iris Dataset...\n")
    
    iris = load_iris()
    X = iris.data
    y = iris.target
    
    # Create DataFrame for better visualization
    df = pd.DataFrame(X, columns=iris.feature_names)
    df['species'] = pd.Categorical.from_codes(y, iris.target_names)
    
    # Display dataset information
    print("="*70)
    print("DATASET INFORMATION")
    print("="*70)
    print(f"Total samples: {len(X)}")
    print(f"Number of features: {X.shape[1]}")
    print(f"Feature names: {list(iris.feature_names)}")
    print(f"Classes: {list(iris.target_names)}")
    print(f"\nClass distribution:")
    for i, name in enumerate(iris.target_names):
        count = np.sum(y == i)
        print(f"  {name}: {count} samples")
    
    print("\n" + "="*70)
    print("FIRST 5 SAMPLES")
    print("="*70)
    print(df.head().to_string())
    
    print("\n" + "="*70)
    print("STATISTICAL SUMMARY")
    print("="*70)
    print(df.describe().to_string())
    
    # Split dataset into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"\n\nTraining samples: {len(X_train)}")
    print(f"Testing samples: {len(X_test)}")
    
    # Feature scaling
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Train multiple models
    print("\n" + "="*70)
    print("TRAINING MODELS")
    print("="*70)
    
    results = {}
    
    # 1. K-Nearest Neighbors
    print("\n1. Training K-Nearest Neighbors (KNN)...")
    knn = KNeighborsClassifier(n_neighbors=5)
    knn.fit(X_train_scaled, y_train)
    y_pred_knn = knn.predict(X_test_scaled)
    accuracy_knn = accuracy_score(y_test, y_pred_knn)
    results['KNN'] = {
        'model': knn,
        'predictions': y_pred_knn,
        'accuracy': accuracy_knn,
        'scaled': True
    }
    print(f"   Accuracy: {accuracy_knn*100:.2f}%")
    
    # 2. Decision Tree
    print("\n2. Training Decision Tree...")
    dt = DecisionTreeClassifier(random_state=42)
    dt.fit(X_train, y_train)
    y_pred_dt = dt.predict(X_test)
    accuracy_dt = accuracy_score(y_test, y_pred_dt)
    results['Decision Tree'] = {
        'model': dt,
        'predictions': y_pred_dt,
        'accuracy': accuracy_dt,
        'scaled': False
    }
    print(f"   Accuracy: {accuracy_dt*100:.2f}%")
    
    # 3. Logistic Regression
    print("\n3. Training Logistic Regression...")
    lr = LogisticRegression(max_iter=200, random_state=42)
    lr.fit(X_train_scaled, y_train)
    y_pred_lr = lr.predict(X_test_scaled)
    accuracy_lr = accuracy_score(y_test, y_pred_lr)
    results['Logistic Regression'] = {
        'model': lr,
        'predictions': y_pred_lr,
        'accuracy': accuracy_lr,
        'scaled': True
    }
    print(f"   Accuracy: {accuracy_lr*100:.2f}%")
    
    # Model comparison
    print("\n" + "="*70)
    print("MODEL COMPARISON")
    print("="*70)
    for model_name, result in results.items():
        print(f"{model_name:25s}: {result['accuracy']*100:.2f}%")
    
    # Find best model
    best_model_name = max(results, key=lambda x: results[x]['accuracy'])
    best_result = results[best_model_name]
    best_accuracy = best_result['accuracy']
    
    print(f"\n{'*'*70}")
    print(f"BEST MODEL: {best_model_name} with {best_accuracy*100:.2f}% accuracy")
    print(f"{'*'*70}")
    
    # Detailed report for best model
    print("\n" + "="*70)
    print(f"CLASSIFICATION REPORT - {best_model_name}")
    print("="*70)
    y_pred_best = best_result['predictions']
    report = classification_report(y_test, y_pred_best, target_names=iris.target_names)
    print(report)
    
    # Confusion matrix
    print("\n" + "="*70)
    print(f"CONFUSION MATRIX - {best_model_name}")
    print("="*70)
    cm = confusion_matrix(y_test, y_pred_best)
    
    print("\n" + " "*15 + "Predicted")
    print(" "*12, end="")
    for name in iris.target_names:
        print(f"{name:>12s}", end="")
    print("\n" + "Actual")
    
    for i, name in enumerate(iris.target_names):
        print(f"{name:>12s}", end="")
        for j in range(len(iris.target_names)):
            print(f"{cm[i][j]:>12d}", end="")
        print()
    
    # Feature importance for Decision Tree
    if 'Decision Tree' in results:
        print("\n" + "="*70)
        print("FEATURE IMPORTANCE - Decision Tree")
        print("="*70)
        feature_importance = results['Decision Tree']['model'].feature_importances_
        importance_pairs = list(zip(iris.feature_names, feature_importance))
        importance_pairs.sort(key=lambda x: x[1], reverse=True)
        
        for feature, importance in importance_pairs:
            bar = '█' * int(importance * 50)
            print(f"{feature:30s}: {importance:.4f} {bar}")
    
    # Example predictions
    print("\n" + "="*70)
    print("PREDICTION EXAMPLES")
    print("="*70)
    print(f"\n{'Actual':<15} {'Predicted':<15} {'Result':<10}")
    print("-" * 40)
    
    num_examples = min(10, len(y_test))
    for i in range(num_examples):
        actual = iris.target_names[y_test[i]]
        predicted = iris.target_names[y_pred_best[i]]
        result = "✓ Correct" if y_test[i] == y_pred_best[i] else "✗ Wrong"
        print(f"{actual:<15} {predicted:<15} {result:<10}")
    
    # Custom prediction
    print("\n" + "="*70)
    print("CUSTOM PREDICTION EXAMPLE")
    print("="*70)
    
    custom_flower = np.array([[5.1, 3.5, 1.4, 0.2]])
    
    if best_result['scaled']:
        custom_flower_processed = scaler.transform(custom_flower)
    else:
        custom_flower_processed = custom_flower
    
    prediction = best_result['model'].predict(custom_flower_processed)
    predicted_species = iris.target_names[prediction[0]]
    
    print(f"\nInput features:")
    print(f"  Sepal Length: {custom_flower[0][0]} cm")
    print(f"  Sepal Width:  {custom_flower[0][1]} cm")
    print(f"  Petal Length: {custom_flower[0][2]} cm")
    print(f"  Petal Width:  {custom_flower[0][3]} cm")
    print(f"\nPredicted species: {predicted_species}")
    
    # Summary statistics
    print("\n" + "="*70)
    print("SUMMARY")
    print("="*70)
    correct_predictions = np.sum(y_test == y_pred_best)
    total_predictions = len(y_test)
    print(f"Total test samples: {total_predictions}")
    print(f"Correct predictions: {correct_predictions}")
    print(f"Wrong predictions: {total_predictions - correct_predictions}")
    print(f"Overall accuracy: {best_accuracy*100:.2f}%")
    
    print("\n" + "="*70)
    print("ANALYSIS COMPLETE!")
    print("="*70)

if __name__ == "__main__":
    main()
